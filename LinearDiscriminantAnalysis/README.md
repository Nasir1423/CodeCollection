# Fisher 线性判别分析（linear discriminant analysis，LDA）

## 1. 原理概述（二分类）

1. **两类线性判别问题**：把所有样本点都投影到**一个方向**上，然后在这个一维空间中确定一个分类的**阈值**。过该阈值点且与投影方向垂直的超平面就是两类的**分类面**。
2. **Fisher 线性判别分析**的基本思想：选择**投影方向**，使投影后**两类样本相隔尽可能远**，而同时**每一类内部的样本又尽可能聚集**。

<img src="https://raw.githubusercontent.com/Nasir1423/blog-img/main/20231118150853.png" style="zoom: 43%;" />

### 1.1 一些概念的定义

> 对于二分类问题，
>
> - **训练样本集**记为 $D=\{x_1,...,x_N\}$，且每个样本是一个 d 维向量
>   - **$w_1$ 类的样本**记为 $D_1=\{x_1^1,...,x_{N_1}^1\}$
>   - **$w_2$ 类的样本**记为 $D_2=\{x_1^2,...,x_{N_2}^2\}$
> - **训练集样本投影后的数据集**记为 $P=\{y_1,...,y_N\}$，且每个样本是一个值
>   - 两类数据分别记为 $P_1,P_2$，定义类似训练样本集

#### 对于原样本空间

> - 基于 Fisher 线性判别的基本思想，对**原样本空间**（即训练样本集）有以下定义
>
>   - 各类的**类均值向量**定义为
>     $$
>     m_i=\frac{1}{N_i}\underset{x_j\in D_i}{\sum}x_j, i=1,2\tag{1.1.1}
>     $$
>
>   - 各类的**类内离散度矩阵**（within-class scatter matrix）定义为
>     $$
>     S_i=\underset{x_j\in D_i}{\sum}(x_j-m_i)(x_j-m_i)^T,i=1,2\tag{1.1.2}
>     $$
>
>     > p.s. 类内离散度的矩阵定义即样本的协方差公式，$S_i=\sum_i$
>
>   - **总类内离散度矩阵**（pooled within-class scatter matrix）定义为
>     $$
>     S_w=S_1+S_2\tag{1.1.3-1}
>     $$
>
>     $$
>     S_w={\sum}_1+{\sum}_2\tag{1.1.3-2}
>     $$
>
>   - **类间离散度矩阵**（between-class scatter matrix）定义为
>     $$
>     S_b=(m_1-m_2)(m_1-m_2)^T\tag{1.1.4}
>     $$
>
>     > p.s. $S_w,S_b$ 都是对称半正定矩阵

#### 对于投影后的一维空间

> - 对**投影后的一维空间**有以下定义
>
>   - 对于选定的投影方向 w（d 维向量），**投影后的样本**记为
>     $$
>     y_i=w^Tx_i,i=1,2,...,N\tag{1.1.5}
>     $$
>
>   - 各类的**类均值**定义为
>     $$
>     \tilde{m}_i=\frac{1}{N_i}\underset{y_j\in P_i}{\sum}y_j=\frac{1}{N_i}\underset{x_j\in D_i}{\sum}w^Tx_j=w^Tm_i,i=1,2\tag{1.1.6}
>     $$
>
>   - 各类的**类内离散度**定义为
>     $$
>     \tilde{S}_i^2=\underset{y_j\in P_i}{\sum}(y_i-\tilde{m}_i)^2,i=1,2\tag{1.1.7}
>     $$
>
>   - **总类内离散度**定义为
>     $$
>     \tilde{S}_w=\tilde{S}_1^2+\tilde{S}_2^2\tag{1.1.8-1}
>     $$
>
>     $$
>     \tilde{S}_w=w^TS_ww\tag{1.1.8-2}
>     $$
>
>   - **类间离散度**定义为
>     $$
>     \tilde{S}_b=(\tilde{m}_1-\tilde{m}_2)^2\tag{1.1.9-1}
>     $$
>
>   $$
>   \tilde{S}_b=w^TS_bw\tag{1.1.9-2}
>   $$

### 1.2 Fisher 准则函数

基于 Fisher 线性判别的基本思想，即希望寻找出一个投影方向，使投影后两类尽可能分开，而各类内部又尽可能聚集，可以得到以下准则，即 **Fisheries 准则函数**（Fisher's Criterion），其中式 1.2.1-2 又称为**广义瑞利商**（generalized Rayleigh quotient）
$$
\underset{w}{max}\ J_F(w)=\frac{\tilde{S}_b}{\tilde{S}_w}=\frac{(\tilde{m}_1-\tilde{m}_2)^2}{\tilde{S}_1^2+\tilde{S}_2^2}\tag{1.2.1-1}
$$

$$
\underset{w}{max}\ J_F(w)=\frac{w^TS_bw}{w^TS_ww}\tag{1.2.1-2}
$$

> p.s. 瑞利商和广义瑞利商
>
> 1. 瑞利商 Rayleigh quotient
>    $$
>    R(A,x)=\frac{x^HAx}{x^Hx}
>    $$
>
>    - x 为非零向量，A 为 n 阶 Hermitan 矩阵。其中，Hermitan 矩阵即满足共轭转置矩阵和自己相等的矩阵，即 $A^H=A$。满足 $A^T=A$ 的实矩阵即 Hermitan 矩阵。
>
>    - 瑞利商的最大值和最小值（$\lambda$ 是指矩阵 A 的特征值）
>      $$
>      \lambda_{min}\le\frac{x^HAx}{x^Hx}\le \lambda_{max}
>      $$
>
> 2. 广义瑞利商 genralized Rayleigh quotient
>    $$
>    R(A,B,x)=\frac{x^HAx}{x^HBx}
>    $$
>
>    - x 为非零向量，A、B 为 n 阶 Hermitan 矩阵，B 为正定矩阵。
>
>    - 广义瑞利商的最大值和最小值（$\lambda$ 是指矩阵 $B^{-1/2}AB^{-1/2}$ or $B^{-1}A$ 的特征值）
>      $$
>      \lambda_{min}\le\frac{x^HAx}{x^HBx}\le \lambda_{max}
>      $$

### 1.3 最优投影方向

因为 Fisher 线性判别的目的是求得使得式 1.2.1 最大的投影方向 w，且 w 的幅值的改变不影响式 1.2.1 的比值和 w 的方向，因此可以将式 1.2.1 的优化问题等价转换为一个**等式约束下的极值问题**如下，
$$
max\ w^TS_bw\tag{1.3.1}\\
s.t.\ w^TS_ww=c\neq0
$$
对式 1.3.1 引入拉格朗日乘子，从而将问题转化为**拉格朗日函数的无约束极值问题**如下，
$$
L(w,\lambda)=w^TS_bw-\lambda(w^TS_ww-c)\tag{1.3.2}
$$

对式 1.3.2 的求解如下，
$$
\frac{\partial L(w,\lambda)}{\partial w}=0\\\\
\Rightarrow S_bw^*-\lambda S_ww^*=0\\\\
\Rightarrow S_w^{-1}S_bw^*=\lambda w^*\\\\
\Rightarrow \lambda w^*= S_w^{-1}(m_1-m_2)(m_1-m_2)^Tw\\\\
\Leftrightarrow w^*= S_w^{-1}(m_1-m_2)\\
p.s.因为 \ (m_1-m_2)^Tw^* 是标量，不影响 w^* 的方向\\\\
$$

> Fisher 判别准则下的**最优投影方向**为
> $$
> w^*= S_w^{-1}(m_1-m_2)\tag{1.3.3}
> $$

### 1.4 分类器的决策规则

样本是正态分布且两类协方差矩阵相同时，**最优贝叶斯分类器**是线性函数 $g(x)=w^Tx+w_0$，其中
$$
w={\sum}^{-1}(\mu_1-\mu_2)\tag{1.4.1}
$$

$$
w_0=-\frac{1}{2}(\mu_1+\mu_2)^T{\sum}^{-1}(\mu_1-\mu_2)-ln\frac{P(w_2)}{P(w_1)}\tag{1.4.2}
$$

**Fisher 线性判别分类器**的决策规则也是一个线性函数，其一般形式为
$$
g(x)=w^Tx+w_0 > 0\ 或 <0\tag{1.4.3}\\
\Rightarrow x\in w_1\ 或\ w_2
$$

#### 决策规则 1

> 在样本为正态分布且两类协方差相同的情况下，类比最优贝叶斯分类器的决策规则，将**样本的算术均值作为真实均值的估计**，将**样本的协方差矩阵作为真实协方差的估计**，则 Fisher 线性判别的方向即最优贝叶斯的方向，此时取阈值为
> $$
> w_0=-\frac{1}{2}(m_1+m_2)^TS_w^{-1}(m_1-m_2)-ln\frac{P(w_2)}{P(w_1)}\\\tag{1.4.4}
> =-\frac{1}{2}(m_1+m_2)^Tw-ln\frac{P(w_2)}{P(w_1)}
> $$
> 此时 Fisher 线性判别分类器的**决策规则**如下，
> $$
> g(x)=w^T[x-\frac{1}{2}(m_1+m_2)] > ln\frac{P(w_2)}{P(w_1)}\ 或 <ln\frac{P(w_2)}{P(w_1)}\\\tag{1.4.5}
> \Rightarrow x\in w_1\ 或\ w_2
> $$
> 把待决策的样本点投影到 Fisher 判别的方向上，通过与两类均值投影的平分点比较做出分类决策。两类先验概率相同的情况下，两类的分界点就是该平分点，否则分界点向先验概率小的一侧偏移。
>
> <img src="https://raw.githubusercontent.com/Nasir1423/blog-img/main/image-20231112191454795.png" alt="image-20231112191454795" style="zoom:43%;" />
>
> p.s. 在样本非正态分布时，该决策规则不能保证最优，但是仍可取得较好分类结果

#### 决策规则 2

> 在**不考虑先验概率**的情况下，此时可以取阈值为投影后两类均值点的中点，即
> $$
> w_0=-\frac{1}{2}(\tilde{m}_1+\tilde{m}_2)\tag{1.4.6}
> $$
> 此时 Fisher 线性判别分类器的**决策规则**如下，
> $$
> g(x)=w^Tx > \frac{1}{2}(\tilde{m}_1+\tilde{m}_2)\ 或 <\frac{1}{2}(\tilde{m}_1+\tilde{m}_2)\\\tag{1.4.7}
> \Rightarrow x\in w_1\ 或\ w_2
> $$

#### 其他阈值取法

$$
w_0=-\frac{n_1\tilde{m}_1+n_2\tilde{m}_2}{n_1+n_2}
$$

$$
w_0=-\frac{1}{2}(\tilde{m}_1+\tilde{m}_2)+\frac{ln\frac{P(w_1)}{P(w_2)}}{n_1+n_2-2}
$$

## 2. Fisher 线性判别的多分类推广

Fisher 线性判别的多分类情况其判别的基本思想不变，即**投影后各类样本相隔尽可能远，而每一类内部的样本又尽可能聚集**，但是此时其投影到的低维空间是一个超平面，且低维空间的维数远小于原有样本空间的维数，又因为投影过程中存在类别信息，因此 LDA 也被当做一种经典**监督降维**技术。

### 2.1 相关概念的定义

> - **训练样本集** $X=\{x_1,x_2,...,x_N\}$，且每个样本是一个 d 维向量，定义 $\mu$ 是**全部训练样本的均值向量**
>
> - 对于每一类，定义 $N_j(j=1,2,...,k)$ 为**第 j 类样本的个数**，$X_j(j=1,2,...,k)$ 为**第 j 类样本的集合**，$\mu_j(j=1,2,...,k)$ 为**第 j 类样本的均值向量**，$\sum_j(j=1,2,...,k)$ 为**第 j 类样本的协方差矩阵**

> - 全局散度矩阵
>   $$
>   S_t=S_w+S_b=\sum_{i=1}^{N}(x_i-\mu)(x_i-\mu)^T\tag{2.1.1}
>   $$
>
> - 类内散度矩阵
>   $$
>   S_w=\sum_{i=1}^{k}S_{wi}=\sum_{i=1}^{k}\underset{x\in X_i}{\sum}(x-\mu_i)(x-\mu_i)^T\tag{2.1.2}
>   $$
>
> - 类间散度矩阵
>   $$
>   S_b=\sum_{i=1}^{k}N_i(\mu_i-\mu)(\mu_i-\mu)^T\tag{2.1.3}
>   $$

### 2.2 Fisher 准则函数

假设投影后的低维空间的维数是 d'，对应的**投影矩阵为 $W=(w_1,w_2,...,w_{d'})$**，投影矩阵 W 是一个 n × d 的矩阵，其中 $w_1,w_2,...,w_{d'}$ 都是 d 维基向量（列向量）。此时 Fisher 准则函数（优化目标为），
$$
\underset{W}{max}\ J_F(W)=\frac{W^TS_bW}{W^TS_wW}\tag{2.2.1}
$$
由于式 2.2.1 无法作为一个标量函数进行优化，为了采用与二类 LDA 类似的优化方法，因此有以下等价的 Fisher 准则函数，
$$
\underset{W}{max}\ J_F(W)=\frac{\underset{diag}\prod W^TS_bW}{\underset{diag}\prod W^TS_wW}\tag{2.2.2}
$$

$$
\underset{W}{max}\ J_F(W)&=&\frac{\prod_{i=1}^{d'} w_i^TS_bw_i}{\prod_{i=1}^{d'} w_i^TS_ww_i}\\
&=&\prod_{i=1}^{d'}\frac{w_i^TS_bw_i}{w_i^TS_ww_i}\tag{2.2.3}
$$

### 2.3 最优投影方向

分析式 2.2.3，发现其为 d' 个广义瑞利商的乘积，而广义瑞利商的最大值为 $S_w^{-1}S_b$ 的最大特征值，该特征值对应的特征向量即投影矩阵的基向量；因此为了最大化式 2.2.3，即使得 d' 个广义瑞利商的乘积最大，此时式 2.2.3 的最大值就是 $S_w^{-1}S_b$ 的最大的 d' 个特征值的乘积，此时**投影矩阵 W 即这最大的 d' 个特征值对应的特征向量组成的矩阵**。

> 多分类 Fisher 判别准则下的**最优投影方向**为
> $$
> W^*=S_w^{-1}S_b 的 d' 个最大非零广义特征值对应的特征向量组成的矩阵，其中d'\le N-1
> $$

p.s. 因为 $S_b$ 的秩最大为 k-1，因此 $S_w^{-1}S_b$ 的 特征向量最多有 k-1 个，因此降维后的最大维数是 k-1，即此时 **LDA 最多把高维数据降低到 “类别-1” 维度的空间中去**。

### 2.4 分类器的决策规则

一般而言，解决多类分类问题有两种思路：一是**把多类问题分解成多个两类问题**，通过多个两类分类器实现多类的分类；二是直接设计**多类分类器**。而第一种解决多类分类问题的实现方式又有两种，第一种做法叫做**一对多**（one-vs-rest 或 one-vs-all），另一种做法叫做**逐对**（pairwise）分类。这里，我们采用一对多的方法建立分类器的决策规则，实现对新的样本类别判别。

假设共有 c 个类别，$w_1,w_2,...,w_c$，如果用一对多的方法实现多分类，则**需要 c 个二分类器就可以实现 c 个类的分类**。每个类别对应一个二分类器，其预测样本属于某一类别的打分（或者说是概率），如果其分值大于零（或某一阈值）则判断该样本属于该类，而且分值越高对此分类月确信，反之则不属于该类，**选择得分最高的分类器，其对应的结果就是待预测的样本的类别**。

假设现在有一个样本 x，c 个分类器 $clf_1,clt_2,...,clf_c$，每个分类器对应一个训练得到的参数 $w,w_0$，分别对样本 x 进行预测，汇总 $w^Tx+w_0$ 的值，即为预测值，如果该值为负，则认为样本 x 不属于该类，否则进行比较，最大的值对应的分类器就是样本 x 对应的类别。



## 3. 算法实现流程

> 输入：
>
> - 数据集 $D=\{(x_1,y_1),...,(x_N,y_N)\}$，其中样 $x_i$ 为 d 维样本列向量，$y_i\in{w_1,...,w_k}$ 为对应样本的类别
> - 降到的维度 d'
>
> 输出：降维后的数据集 D

> 1. 计算**类内离散度矩阵** $S_w$ 和**类间离散度矩阵** $S_b$
> 2. 计算矩阵 $S_w^{-1}S_b$ 的**最大的 d' 个特征值和对应的 d' 个特征向量**，得到**投影矩阵** W
> 3. 将数据**投影**到 d' 维空间，即 $D_{projected}=W^TX$，并输出。其中 X 是样本数据集。

